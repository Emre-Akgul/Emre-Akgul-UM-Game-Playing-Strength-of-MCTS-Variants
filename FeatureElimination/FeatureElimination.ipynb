{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from Models.LinearRegression import LinearRegression\n",
    "from Utils.Preprocessor import Preprocessor\n",
    "from Utils.Utils import root_mean_squared_error, train_test_split, initial_preprocessing\n",
    "from Utils.FeatureEliminators.VarianceEliminator import VarianceEliminator\n",
    "from Utils.FeatureEliminators.CorrelationEliminator import CorrelationEliminator\n",
    "from Utils.FeatureEliminators.LassoEliminator import LassoEliminator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "train = pd.read_csv('../Data/train.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary features based on exploratory data analysis part 1.\n",
    "train = initial_preprocessing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"num_wins_agent1\", \"num_draws_agent1\", \"num_losses_agent1\", \"utility_agent1\"], axis=1)\n",
    "y = train[\"utility_agent1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_valid, y_train, y_valid= train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "preprocessor = Preprocessor(normalize=True, one_hot_encode=True)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=preprocessor.get_column_names())\n",
    "\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "X_valid = pd.DataFrame(X_valid, columns=preprocessor.get_column_names())\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder: Linear Regression Baseline\n",
    "Linear Regression: \\\n",
    "Train mean squared error:  0.5175135945021986 \\\n",
    "Validation mean squared error:  0.51911678407925\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Variance Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_eliminator = VarianceEliminator(X_train, y_train, threshold=0.01)\n",
    "\n",
    "selected_features = variance_eliminator.get_feature_indices()\n",
    "variance_1_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_var_1 = X_train.iloc[:, selected_features]\n",
    "X_test_var_1 = X_valid.iloc[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  336\n",
      "Train mean squared error:  0.5306881182466742\n",
      "Validation mean squared error:  0.5315929002975792\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_var_1 = X_train_var_1.to_numpy()\n",
    "X_test_var_1 = X_test_var_1.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_var_1, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_var_1)\n",
    "test_pred = lr_model.predict(X_test_var_1)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_eliminator = VarianceEliminator(X_train, y_train, threshold=0.1)\n",
    "\n",
    "variance_2_selected_features = variance_eliminator.get_feature_indices()\n",
    "variance_2_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_var_2 = X_train.iloc[:, variance_2_selected_features]\n",
    "X_test_var_2 = X_valid.iloc[:, variance_2_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  135\n",
      "Train mean squared error:  0.5995919481377527\n",
      "Validation mean squared error:  0.6004933618410249\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_var_2 = X_train_var_2.to_numpy()\n",
    "X_test_var_2 = X_test_var_2.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_var_2, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_var_2)\n",
    "test_pred = lr_model.predict(X_test_var_2)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(variance_2_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Correlation Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_eliminator_1 = CorrelationEliminator(X_train, y_train, correlation_threshold=0.01)\n",
    "\n",
    "corr_1_selected_features = correlation_eliminator_1.get_feature_indices()\n",
    "corr_1_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_corr_1 = X_train.iloc[:, corr_1_selected_features]\n",
    "X_test_corr_1 = X_valid.iloc[:, corr_1_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  269\n",
      "Train mean squared error:  0.5324470589299449\n",
      "Validation mean squared error:  0.5340079095469382\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_corr_1 = X_train_corr_1.to_numpy()\n",
    "X_test_corr_1 = X_test_corr_1.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_corr_1, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_corr_1)\n",
    "test_pred = lr_model.predict(X_test_corr_1)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(corr_1_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_eliminator_2 = CorrelationEliminator(X_train, y_train, correlation_threshold=0.03)\n",
    "\n",
    "corr_2_selected_features = correlation_eliminator_2.get_feature_indices()\n",
    "corr_2_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_corr_2 = X_train.iloc[:, corr_2_selected_features]\n",
    "X_test_corr_2 = X_valid.iloc[:, corr_2_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  76\n",
      "Train mean squared error:  0.5435803901515012\n",
      "Validation mean squared error:  0.5459862384342256\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_corr_2 = X_train_corr_2.to_numpy()\n",
    "X_test_corr_2 = X_test_corr_2.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_corr_2, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_corr_2)\n",
    "test_pred = lr_model.predict(X_test_corr_2)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(corr_2_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Lasso Eliminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.13552179  0.02149179  0.11688832  0.16142764  0.14623113  0.01796757\n",
      "  0.1113351   0.11391161  0.1923999   0.04881386  0.06050701  0.1018681\n",
      "  0.13681556  0.11160901  0.07684827  0.11741258  0.01044977  0.11186196\n",
      "  0.11483097  0.15622347  0.08205623  0.14635023  0.05739204  0.08710357\n",
      "  0.07569954  0.09478641  0.1297759   0.18853078  0.1891266   0.14133835\n",
      "  0.08463799  0.17882477  0.10489186  0.12998745  0.13694414  0.0698415\n",
      "  0.00619916  0.15315166  0.02944366  0.13845117  0.07925201  0.09499829\n",
      "  0.15445651  0.16561626  0.06081209  0.09665804  0.15203817  0.08992225\n",
      "  0.15694487  0.12784079  0.15107906  0.12806633  0.08822729  0.10078291\n",
      "  0.12364622  0.10764498  0.16030872  0.15049549  0.10799672  0.0659031\n",
      "  0.08504493  0.08652476  0.08674783  0.10277922  0.08287242  0.10177741\n",
      "  0.12764416  0.15273395  0.18068018  0.03388803  0.04657592  0.09750169\n",
      "  0.11119865  0.16289446  0.1266719   0.06039922  0.20080504  0.11491901\n",
      "  0.11263063  0.07832645  0.18133908  0.0340257   0.09193703  0.06525175\n",
      "  0.09822193  0.20388626  0.02764843  0.11497806  0.11825248  0.19881176\n",
      "  0.02146293  0.17786883  0.07251272  0.21708801  0.15045711  0.10601176\n",
      "  0.16099588  0.1200955   0.11555721  0.14431836  0.10207977  0.06959035\n",
      "  0.1809585   0.011074    0.13283803  0.03096522  0.10420688  0.18956369\n",
      "  0.15817238  0.11072388 -0.00926077  0.12039316  0.00165132  0.05312584\n",
      "  0.13943678  0.16495492  0.00839271  0.18571137  0.12976116  0.03706634\n",
      "  0.08674848  0.11579154  0.08026062  0.06062839  0.16908196  0.01967531\n",
      "  0.07547755  0.007593    0.16677166  0.1000725   0.11048152  0.07336858\n",
      "  0.07053084  0.10847259  0.03598092  0.06032678  0.14591913  0.10653537\n",
      "  0.13656634  0.05272619  0.13594193  0.08765369  0.03671393  0.1942561\n",
      "  0.13120839  0.03701577  0.07322565  0.02095073  0.15258578  0.18813455\n",
      "  0.03453212  0.15005635  0.07043409  0.12958094  0.08632367  0.12674242\n",
      "  0.15788411  0.14694917  0.04014536  0.13367194  0.12442347  0.0038313\n",
      "  0.03280323  0.03746999  0.04281473  0.15378141  0.13780893  0.11159554\n",
      "  0.20312148  0.05384857  0.00403501  0.02229938  0.20000953  0.13085696\n",
      "  0.03504269  0.03429803  0.184559    0.00434917  0.05027652  0.12041942\n",
      "  0.09122861  0.05832075  0.14236742  0.1146575   0.16560366  0.18494584\n",
      "  0.03583592  0.08978616  0.11322769  0.12213748  0.08466571  0.10437175\n",
      "  0.1926619   0.03107434  0.0158054   0.1821868   0.17292459  0.0407738\n",
      "  0.17090361  0.03916517  0.0936268   0.03737095  0.09848102  0.01458597\n",
      "  0.11134376  0.04611329  0.08961671  0.01898037  0.11788122  0.14840339\n",
      "  0.07427145  0.17736794 -0.01530898  0.10693655  0.01647102  0.00479298\n",
      "  0.09786134  0.09821868  0.07913914  0.10106255  0.07453671  0.12449226\n",
      "  0.0161581   0.09156013  0.05523296  0.0479581   0.04135815  0.12337228\n",
      "  0.18167571  0.00372079  0.0263358   0.10564526  0.01118753  0.00547231\n",
      "  0.16937085  0.02190426  0.01755836  0.09074072  0.02026073  0.1159723\n",
      "  0.04937347  0.13561838  0.04467536  0.13025686  0.08851839  0.03926909\n",
      "  0.1897086   0.08050483  0.0678328   0.15643756  0.08384776  0.17959427\n",
      "  0.06605554  0.19470191  0.07089024  0.08210778  0.15066499  0.1810906\n",
      "  0.14227643  0.07165513  0.07437245  0.05036457  0.11286957  0.11240592\n",
      "  0.1454652   0.13142299  0.1274111   0.17359252  0.08144403  0.10673766\n",
      "  0.12871717  0.01159858  0.03284196  0.17976023  0.17278953  0.17290816\n",
      "  0.12364297  0.16225161  0.04622489  0.08271693  0.14107504  0.15484103\n",
      "  0.09236438  0.09804277  0.00935422  0.1051001   0.15804121  0.18011963\n",
      " -0.00312998  0.15361591  0.15895367  0.08778917  0.09845506  0.06695782\n",
      "  0.02340448  0.05182707  0.06001178  0.02542201  0.15295824  0.19291713\n",
      "  0.06709593  0.13021     0.02076179  0.11271269  0.10371671  0.16882639\n",
      "  0.0728765   0.09509548  0.03329521  0.13429411  0.08323781  0.10571697\n",
      "  0.17320509  0.13022909  0.08930354  0.07747425  0.09142393  0.1944306\n",
      "  0.13201791  0.00546097  0.00731161  0.03551936  0.07657924  0.02107972\n",
      "  0.11752555  0.15331939  0.19671176  0.15815888  0.07952654  0.19829111\n",
      "  0.05208508  0.1548254   0.0433878   0.04840606  0.07563882  0.12786109\n",
      "  0.02224687  0.19316665  0.16529553  0.00895352  0.04491673  0.08696637\n",
      "  0.05509529  0.1866076   0.05144486  0.02204573  0.04770558  0.04116255\n",
      "  0.00727053  0.06826192  0.02630877  0.15090865  0.09059326  0.06144195\n",
      "  0.07454626  0.13197052  0.11503857  0.16133028  0.14173552  0.16004908\n",
      "  0.12541064  0.1154226   0.11499417  0.02573741  0.09476009  0.1241944\n",
      "  0.10123948  0.12569943  0.18155137  0.14738964  0.19021858  0.15171975\n",
      "  0.04241968  0.16803576  0.1961636   0.15398526  0.07590325  0.12702162\n",
      "  0.07439239  0.09085987  0.05787898  0.19273227  0.00996201  0.07062755\n",
      "  0.06726398  0.11649741 -0.00106699  0.04336187  0.06637326  0.03312406\n",
      "  0.06437552  0.09744197  0.19206391  0.03851278  0.03449003  0.04679742\n",
      "  0.13104915  0.06231211  0.18144594  0.03972996  0.10997556  0.05897309\n",
      "  0.08708448  0.02824526  0.10941861  0.14468907  0.1463913   0.13572304\n",
      "  0.19830181  0.14721138  0.12042991  0.15581618  0.11996019  0.00470378\n",
      "  0.10059404  0.13718865  0.13394278  0.16447295  0.1918932   0.17134707\n",
      "  0.02197618  0.16536728  0.14211579  0.00573074  0.01035321  0.03000766\n",
      "  0.07755721  0.08767201  0.1036825   0.07182511  0.03587247  0.04769984\n",
      "  0.01134777  0.06371858  0.09040709  0.05798758  0.03966296  0.16595876\n",
      "  0.02409586  0.16560866  0.12288205  0.09782696  0.2051878   0.07591938\n",
      "  0.0902536   0.09250741  0.06931574  0.09073497  0.08140214  0.07827342\n",
      "  0.07993062  0.17668989  0.14610613  0.11618987  0.07723556  0.06918984\n",
      "  0.18731162  0.00388141  0.16018058  0.12340641  0.06082741  0.19633971\n",
      "  0.18827331  0.05437646  0.14614665  0.04943624  0.03137055  0.0204333\n",
      "  0.16059271  0.13673349  0.13040483  0.03784311  0.17598598  0.05183726\n",
      "  0.13305806  0.1374354   0.13212313  0.08839208  0.02540905  0.16033266\n",
      "  0.08023279  0.19358235  0.18360645  0.06238298  0.04553452  0.02396638\n",
      "  0.16885695  0.15139182  0.15672947  0.12588303  0.13855514  0.02556475\n",
      "  0.19369088  0.00044133  0.0610748   0.18112371  0.13232224  0.17434462\n",
      "  0.17979058  0.03395852  0.18062137  0.13834429  0.19992668  0.0554783\n",
      "  0.13211343  0.04618625  0.10824175  0.15255093  0.02897337  0.07589165\n",
      "  0.04103478  0.01454387  0.14199862  0.06642245  0.12089952  0.01114609\n",
      "  0.1343486   0.00593072  0.18475087  0.12548888  0.04147205  0.0704289\n",
      "  0.18508754  0.13879835  0.15936482  0.09229368  0.06220764  0.14789899\n",
      "  0.10250154  0.14056301  0.12194206  0.16316781  0.15525279  0.14984782\n",
      "  0.18562503  0.12771595  0.12933814  0.13194491  0.16648264  0.06098771\n",
      "  0.11317035  0.18463677  0.12824283  0.01815895  0.07108214  0.13929435\n",
      "  0.12118256  0.02961345  0.09449484  0.12059266  0.02558229  0.06826433\n",
      "  0.09348342  0.14850287  0.05272725  0.0913839   0.18616417  0.08586291\n",
      "  0.03478689  0.10217245  0.0945887   0.12608719  0.09669631  0.05870934]\n"
     ]
    }
   ],
   "source": [
    "lasso_eliminator = LassoEliminator(X_train, y_train, l1=1, threshold=1e-1)\n",
    "\n",
    "lasso_selected_features = lasso_eliminator.get_feature_indices()\n",
    "lasso_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_lasso = X_train.iloc[:, lasso_selected_features]\n",
    "X_test_lasso = X_valid.iloc[:, lasso_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  290\n",
      "Train mean squared error:  0.5961747512502205\n",
      "Validation mean squared error:  0.5960908241963463\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_lasso = X_train_lasso.to_numpy()\n",
    "X_test_lasso = X_test_lasso.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_lasso, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_lasso)\n",
    "test_pred = lr_model.predict(X_test_lasso)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(lasso_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Mutual information eliminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.FeatureEliminators.MutualInformationEliminator import MutualInformationEliminator\n",
    "mutual_info_eliminator = MutualInformationEliminator(X_train, y_train, threshold=0.01)\n",
    "\n",
    "mutual_info_selected_features = mutual_info_eliminator.get_feature_indices()\n",
    "mutual_info_mask = mutual_info_eliminator.get_feature_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  50\n",
      "Train mean squared error:  0.555158807269044\n",
      "Validation mean squared error:  0.5569853990675582\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_mutual_info = X_train.iloc[:, mutual_info_selected_features]\n",
    "X_test_mutual_info = X_valid.iloc[:, mutual_info_selected_features]\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_mutual_info, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_mutual_info)\n",
    "test_pred = lr_model.predict(X_test_mutual_info)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(mutual_info_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
