{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Initial Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from Models.LinearRegression import LinearRegression\n",
    "from Utils.Preprocessor import Preprocessor\n",
    "from Utils.Utils import root_mean_squared_error, train_test_split, initial_preprocessing\n",
    "from Utils.FeatureEliminators.VarianceEliminator import VarianceEliminator\n",
    "from Utils.FeatureEliminators.CorrelationEliminator import CorrelationEliminator\n",
    "from Utils.FeatureEliminators.LassoEliminator import LassoEliminator\n",
    "from Utils.FeatureEliminators.MutualInformationEliminator import MutualInformationEliminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "train = pd.read_csv('../Data/train.csv', index_col='Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary features based on exploratory data analysis part 1.\n",
    "train = initial_preprocessing(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"num_wins_agent1\", \"num_draws_agent1\", \"num_losses_agent1\", \"utility_agent1\"], axis=1)\n",
    "y = train[\"utility_agent1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_valid, y_train, y_valid= train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "preprocessor = Preprocessor(normalize=False, one_hot_encode=True)\n",
    "\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=preprocessor.get_column_names())\n",
    "\n",
    "X_valid = preprocessor.transform(X_valid)\n",
    "X_valid = pd.DataFrame(X_valid, columns=preprocessor.get_column_names())\n",
    "\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_valid.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder: Linear Regression Baseline\n",
    "Linear Regression: \\\n",
    "Train mean squared error:  0.5175135945021986 \\\n",
    "Validation mean squared error:  0.51911678407925\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminate High Correlation Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already computed the correlation matrix before using np. \n",
    "correlation_matrix = X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "386\n"
     ]
    }
   ],
   "source": [
    "# Identify features to keep based on the algorithm\n",
    "selected_features = set(X_train.columns)\n",
    "\n",
    "for col in correlation_matrix.columns:\n",
    "    if col in selected_features:\n",
    "        # Find features highly correlated with the current feature\n",
    "        correlated_features = correlation_matrix.index[\n",
    "            correlation_matrix[col].abs() > 0.8\n",
    "        ].tolist()\n",
    "\n",
    "        if len(correlated_features) > 1:\n",
    "            # Compare their absolute correlation with the target variable\n",
    "            best_feature = max(correlated_features, key=lambda feature: abs(X_train[feature].corr(y_train)))\n",
    "            \n",
    "            # Remove all except the best feature from the set\n",
    "            selected_features -= set(correlated_features) - {best_feature}\n",
    "\n",
    "# Convert selected_features to a list for indexing\n",
    "selected_features = list(selected_features)\n",
    "print(len(selected_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the selected features\n",
    "X_train = X_train[selected_features]\n",
    "X_valid = X_valid[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Variance Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_eliminator = VarianceEliminator(X_train, y_train, threshold=0.01)\n",
    "\n",
    "selected_features = variance_eliminator.get_feature_indices()\n",
    "variance_1_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_var_1 = X_train.iloc[:, selected_features]\n",
    "X_test_var_1 = X_valid.iloc[:, selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  246\n",
      "Train mean squared error:  0.6242887537202013\n",
      "Validation mean squared error:  0.6243533341402387\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_var_1 = X_train_var_1.to_numpy()\n",
    "X_test_var_1 = X_test_var_1.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_var_1, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_var_1)\n",
    "test_pred = lr_model.predict(X_test_var_1)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 1 version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_eliminator = VarianceEliminator(X_train, y_train, threshold=0.03)\n",
    "\n",
    "variance_2_selected_features = variance_eliminator.get_feature_indices()\n",
    "variance_2_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_var_2 = X_train.iloc[:, variance_2_selected_features]\n",
    "X_test_var_2 = X_valid.iloc[:, variance_2_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  200\n",
      "Train mean squared error:  0.6242887537202013\n",
      "Validation mean squared error:  0.6243533341402387\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_var_2 = X_train_var_2.to_numpy()\n",
    "X_test_var_2 = X_test_var_2.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_var_2, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_var_2)\n",
    "test_pred = lr_model.predict(X_test_var_2)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(variance_2_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Correlation Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_eliminator_1 = CorrelationEliminator(X_train, y_train, correlation_threshold=0.01)\n",
    "\n",
    "corr_1_selected_features = correlation_eliminator_1.get_feature_indices()\n",
    "corr_1_mask = correlation_eliminator_1.get_feature_mask()\n",
    "\n",
    "X_train_corr_1 = X_train.iloc[:, corr_1_selected_features]\n",
    "X_test_corr_1 = X_valid.iloc[:, corr_1_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  192\n",
      "Train mean squared error:  0.5367566287134902\n",
      "Validation mean squared error:  0.538758615168941\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_corr_1 = X_train_corr_1.to_numpy()\n",
    "X_test_corr_1 = X_test_corr_1.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_corr_1, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_corr_1)\n",
    "test_pred = lr_model.predict(X_test_corr_1)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(corr_1_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2 Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_eliminator_2 = CorrelationEliminator(X_train, y_train, correlation_threshold=0.03)\n",
    "\n",
    "corr_2_selected_features = correlation_eliminator_2.get_feature_indices()\n",
    "corr_2_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_corr_2 = X_train.iloc[:, corr_2_selected_features]\n",
    "X_test_corr_2 = X_valid.iloc[:, corr_2_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  59\n",
      "Train mean squared error:  0.5445587904045704\n",
      "Validation mean squared error:  0.5469917126963312\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_corr_2 = X_train_corr_2.to_numpy()\n",
    "X_test_corr_2 = X_test_corr_2.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_corr_2, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_corr_2)\n",
    "test_pred = lr_model.predict(X_test_corr_2)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(corr_2_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Lasso Eliminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.69805389e-01  2.03949171e-02  3.96465439e+00  2.90878348e-01\n",
      "  3.27306547e-02  4.59094201e+00  3.01376723e+00  6.58437046e+00\n",
      "  4.96482188e+00  7.17253834e+00  8.51916751e+00  4.98510124e+00\n",
      "  2.78335847e-02  6.65722053e-03  2.04861943e+00  1.00872846e-01\n",
      "  4.26635937e+01  5.00537957e-03  1.97903324e+01  1.49331964e-02\n",
      "  3.56773624e-02  4.40287334e-02  2.42826327e+00  2.75116279e-01\n",
      "  8.94380098e+03  3.52659293e+01  5.61549966e-02  8.50019143e-02\n",
      "  1.15474676e+00  2.06801190e-01  2.80266349e+00  5.21190577e-02\n",
      "  9.25653157e-03  7.81407345e-03  3.20719160e-02  7.45465314e-01\n",
      "  2.46264432e-02  1.31089920e-01  2.43169438e-02  3.01967421e+00\n",
      "  4.20489483e-01  2.47055319e+00  3.15967750e+00  1.19322714e-02\n",
      "  3.70582541e+00  1.26564783e-01  5.87704224e-01  9.86894890e-01\n",
      "  3.04424869e-01  2.50865392e+00  1.88374382e+00  1.93602816e-01\n",
      "  1.55095764e-01  2.05889346e-02  1.48107955e-02  6.97740662e-01\n",
      "  4.76131396e-02  1.99352955e-02  9.11313114e-02  5.80534494e+02\n",
      "  2.46143608e+00  6.12389221e-01  2.53037157e-02  1.64949603e-02\n",
      "  1.17451666e+00  2.03770507e+02  8.39751854e-03  2.92579678e+00\n",
      "  5.58099702e-03  4.04619036e+02  3.06741226e-01  8.09976706e-01\n",
      "  4.31449048e+00  3.87071415e-02  2.04258894e-02  2.80960555e-02\n",
      "  2.03405212e-01  3.49821896e+00  2.96187187e-01  1.59558705e-02\n",
      "  1.08125119e+00  8.70152900e-01  5.49056347e-02  7.54882636e-02\n",
      "  7.28699419e-02  1.86611604e-01  2.26614378e-02  2.94148922e-02\n",
      "  1.89787091e+01  3.10235499e-03  6.78507173e-03  9.89380907e-01\n",
      "  1.11665764e-02  9.73163343e-01  1.36307909e-01  8.81837538e-01\n",
      "  3.18558243e+00  8.30041354e-02  1.19070271e-02  1.75289647e+00\n",
      "  7.97206725e-02  3.40048280e-02  2.50781258e+02  9.66760167e-01\n",
      "  7.53453751e-03  5.08999414e-01  3.32501295e-01  2.91874714e+00\n",
      "  1.73031310e+00  1.63859587e+01  4.06457979e-02  4.79210894e+00\n",
      "  1.19732910e-02  5.52868344e-03  9.71022571e-03  1.26500883e+00\n",
      "  1.18387673e-02  3.35027811e-02  9.21607962e-03  9.94725263e-01\n",
      "  2.14807742e-02  1.37053144e-01  1.22902782e+00 -4.14836735e+01\n",
      "  1.15564431e-02  4.14771075e+00  5.83945439e-01  8.26612336e-01\n",
      "  7.04963600e-02  3.91702048e-03  1.94700355e-02  2.42844966e+02\n",
      "  5.28964933e+00  6.46878047e-03  1.81624233e-02  2.31892279e+01\n",
      "  3.64972334e-01  3.12041109e-01  3.28093065e-02  2.28375985e+00\n",
      "  3.79018085e-02  1.59058699e+02  1.78950152e-02  1.69483518e+00\n",
      "  8.65454339e-01  1.30074798e+00  8.51698331e-04  4.99215639e-02\n",
      "  1.72932599e+00  1.85120138e-02  4.25107802e-01  2.31875018e-01\n",
      "  1.92737119e+01  3.83670320e-02  1.34830902e+00  2.18833345e+00\n",
      "  1.58924470e-01  3.85811784e-01  2.45601976e+00  1.78438025e+00\n",
      "  5.84044932e+00  4.94021453e-03  2.06560830e-01  1.00993658e-02\n",
      "  3.56212731e+00  3.00394526e-01  2.73807309e+00  1.28762369e-02\n",
      "  1.09297096e-01  2.94532484e-01  2.15003872e-02  4.07510052e+00\n",
      "  8.96288147e-01  1.23930196e+00  2.62449242e-02  5.50689615e+00\n",
      "  6.79649175e+00  7.62847700e-02  1.39627585e-02  5.16434349e+00\n",
      "  1.86157158e-02  2.67505478e-02  3.74353485e-01  5.65698485e-03\n",
      "  9.37044004e-03  2.73808258e-02  5.28176232e-02  2.32437830e-02\n",
      "  7.90064587e-01  1.31961142e-01  1.01884729e+00  7.71068272e-02\n",
      "  7.52040107e-01  1.87942250e-02  1.95415884e+00  2.89900888e-01\n",
      "  1.63379402e+00  3.13759170e-01  1.02176642e+00  1.08567415e-02\n",
      "  1.89093084e+00  2.05106716e-02  2.71149728e+00  1.08602732e-02\n",
      "  1.09538231e-01  1.27641157e-02  2.01689533e-02  4.59068561e+00\n",
      "  2.05044009e-02  9.61208936e+00  4.45391248e-01  4.89066140e+00\n",
      "  7.10471956e-01  1.44678514e+13  2.26156156e+00  1.55390318e-02\n",
      "  1.37498331e-01  7.13694474e-02  1.89221232e-01  3.54916771e+00\n",
      "  7.75338558e-02  4.36589870e+02  3.25659185e-01  3.58441410e-02\n",
      "  4.74219341e-01  2.46482143e+02  5.46840353e-02  7.07903745e-01\n",
      "  1.36164210e-02  1.21774755e-02  6.03621046e-02  1.24642477e-02\n",
      "  6.01156440e-02  3.19457736e+00  1.55629879e-01  1.21100086e+00\n",
      "  1.08706776e+01  1.37349154e-01  3.51947576e-01  8.90363693e-01\n",
      "  2.46928822e-02  9.79578085e-01  1.35942919e+00  1.64672801e-02\n",
      "  1.14699730e+00  1.21713671e-01  2.31043647e-01  6.45288054e-01\n",
      " -1.43272360e+02  3.54447915e+00  5.30550877e+00  9.63139946e-03\n",
      "  3.74649015e+00  2.49780031e+00  7.03094855e-01  7.96339756e-02\n",
      "  1.66640447e-02  6.37053078e+00  1.78417668e+00  3.73060199e-02\n",
      "  7.02956539e-01  5.04446119e-02  6.37616867e-03  3.90268704e-02\n",
      "  8.31709669e-03  7.52416616e-01  2.67237644e-02  5.99385359e-03\n",
      "  1.54633999e+00  3.08619236e-01  1.87340126e-02  2.13609614e-02\n",
      "  1.32721657e-03  6.58397323e-02  2.79159343e+00  3.41873625e+03\n",
      "  4.92186550e+00  5.10576397e+02  5.40919009e-01  6.30389031e-01\n",
      "  1.08402804e+01  1.08399266e-01  4.24766882e-02  5.64515841e-02\n",
      "  1.73306958e+00  1.30233786e+00  9.95461698e-02  1.09281718e-02\n",
      "  1.79142888e+00  1.31571598e-01  7.36612065e-02  5.90425504e-01\n",
      "  1.88053857e-01  2.27095716e-02  2.13800905e-01  4.77437360e+01\n",
      "  2.94362643e+00  1.74088322e+00  5.97115664e-03  7.72743792e-03\n",
      "  1.05245689e-02  7.84391321e-02  1.59451096e-02  7.23498325e-03\n",
      "  2.44840577e+00  1.01214930e-01  2.44225873e+00  5.11668791e-02\n",
      "  3.26093997e+00  2.79626493e+00  1.03880272e-02  1.12112207e+00\n",
      "  3.69520905e-01  6.65665346e+01  1.13317451e-01  5.02158595e+00\n",
      "  1.29256434e+00  2.92168411e+00  1.79092960e+00  6.92445816e-01\n",
      "  3.41137392e-02  9.68177260e-01  3.32153666e-02  1.97311136e+00\n",
      "  2.82415382e+00  8.66508600e-03  1.03550232e+00  1.81439903e-02\n",
      "  2.69033049e-02  8.98850908e-01  4.19229024e+00  4.17187802e-02\n",
      "  5.39955763e+00  6.29657009e-01  6.10637104e-01  5.25248324e+00\n",
      "  5.73737177e+00  2.09167162e-01  1.12251139e+00  1.60773218e-01\n",
      "  2.43457942e-01  4.83836576e-01  7.19544611e-02  2.57651021e-01\n",
      "  1.29695036e+00  5.44694656e-01  7.80287003e-02  1.32520581e-02\n",
      "  8.97895017e-02  4.20193276e+00  2.88726841e-03  3.26913024e-01\n",
      "  9.61677541e-02  5.29476350e-02  3.26345456e-01  1.09008909e+00\n",
      "  3.47962573e-02  1.98545978e-02  3.13996475e-02  2.00642506e+04\n",
      "  1.06040757e-02  5.21982773e+00  1.67079342e-02  6.68126895e-01\n",
      "  1.57203815e+00  2.66125992e+00  2.49325163e-01  3.29104059e-01\n",
      "  1.27348163e-02  1.25440976e-01  2.34076271e+00  2.02730982e+01\n",
      "  2.98574013e-02  7.24200438e+00  2.83914573e-02  6.46397440e+00\n",
      "  6.95084469e-03  6.94939063e-02  8.18056808e-03  6.37812184e-02\n",
      "  2.60160932e-01  3.29186785e-02  3.79792400e+00  4.00171645e+00\n",
      "  4.87404302e-02  2.47060812e+00]\n"
     ]
    }
   ],
   "source": [
    "lasso_eliminator = LassoEliminator(X_train, y_train, l1=0.1, threshold=0.02)\n",
    "\n",
    "lasso_selected_features = lasso_eliminator.get_feature_indices()\n",
    "lasso_mask = variance_eliminator.get_feature_mask()\n",
    "\n",
    "X_train_lasso = X_train.iloc[:, lasso_selected_features]\n",
    "X_test_lasso = X_valid.iloc[:, lasso_selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  316\n",
      "Train mean squared error:  0.6242887537202013\n",
      "Validation mean squared error:  0.6243533341402387\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_lasso = X_train_lasso.to_numpy()\n",
    "X_test_lasso = X_test_lasso.to_numpy()\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_lasso, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_lasso)\n",
    "test_pred = lr_model.predict(X_test_lasso)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(lasso_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Mutual information eliminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutual_info_eliminator = MutualInformationEliminator(X_train, y_train, threshold=0.01)\n",
    "\n",
    "mutual_info_selected_features = mutual_info_eliminator.get_feature_indices()\n",
    "mutual_info_mask = mutual_info_eliminator.get_feature_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  26\n",
      "Train mean squared error:  0.5562532752314526\n",
      "Validation mean squared error:  0.5582367407746373\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_mutual_info = X_train.iloc[:, mutual_info_selected_features]\n",
    "X_test_mutual_info = X_valid.iloc[:, mutual_info_selected_features]\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_mutual_info, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_mutual_info)\n",
    "test_pred = lr_model.predict(X_test_mutual_info)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(mutual_info_selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6892/3936579794.py:13: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if lasso_mask[i]:\n",
      "/tmp/ipykernel_6892/3936579794.py:15: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if corr_2_mask[i]:\n",
      "/tmp/ipykernel_6892/3936579794.py:17: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  if variance_2_mask[i]:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# majority voting for feature selection\n",
    "# mutual_info_mask have 2 vote\n",
    "# lasso_mask have 1 vote\n",
    "# corr_2_mask have 1 vote\n",
    "# variance_2_mask have 1 vote\n",
    "# vote > 2 -> selected\n",
    "\n",
    "selected_features = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    vote = 0\n",
    "    if mutual_info_mask[i]:\n",
    "        vote += 3\n",
    "    if lasso_mask[i]:\n",
    "        vote += 1\n",
    "    if corr_2_mask[i]:\n",
    "        vote += 1\n",
    "    if variance_2_mask[i]:\n",
    "        vote += 1\n",
    "    if vote > 2:\n",
    "        selected_features.append(i)\n",
    "\n",
    "selected_features = np.array(selected_features)\n",
    "selected_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: \n",
      "Number of used featues:  202\n",
      "Train mean squared error:  0.6242887537202013\n",
      "Validation mean squared error:  0.6243533341402387\n"
     ]
    }
   ],
   "source": [
    "# to numpy array\n",
    "X_train_final= X_train.iloc[:, selected_features]\n",
    "X_test_final = X_valid.iloc[:, selected_features]\n",
    "\n",
    "lr_model = LinearRegression(fit_method=\"ols\", loss_function=\"rmse\")\n",
    "\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "train_pred = lr_model.predict(X_train_final)\n",
    "test_pred = lr_model.predict(X_test_final)\n",
    "\n",
    "print(\"Linear Regression: \")\n",
    "print(\"Number of used featues: \", len(selected_features))\n",
    "print(\"Train mean squared error: \", root_mean_squared_error(y_train, train_pred))\n",
    "print(\"Validation mean squared error: \", root_mean_squared_error(y_valid, test_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
